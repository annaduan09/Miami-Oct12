---
title: "Miami Home Sale Price Prediction"
author: "Anna Duan, Bingchu Chen"
date: "10/16/2020"
output: html_document
---
# Introduction
```{r Setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
####load libraries, etc
library(tidyverse)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(knitr)
library(gridExtra)
library(ggcorrplot)
library(stargazer)
library(mapview)
library(osmdata)
library(tidycensus)
library(tidygeocoder)
library(raster)
library(rnaturalearth)
library(RColorBrewer)
library(rnaturalearthdata)
library(geosphere)

mapTheme <- function(base_size = 12) {
  theme(
    text = element_text( color = "black"),
    plot.title = element_text(size = 14,colour = "black"),
    plot.subtitle=element_text(face="italic"),
    plot.caption=element_text(hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_blank(),axis.title = element_blank(),
    axis.text = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=2)
  )
}

plotTheme <- function(base_size = 12) {
  theme(
    text = element_text( color = "black"),
    plot.title = element_text(size = 14,colour = "black"),
    plot.subtitle = element_text(face="italic"),
    plot.caption = element_text(hjust=0),
    axis.ticks = element_blank(),
    panel.background = element_blank(),
    panel.grid.major = element_line("grey80", size = 0.1),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "black", fill=NA, size=2),
    strip.background = element_rect(fill = "grey80", color = "white"),
    strip.text = element_text(size=12),
    axis.title = element_text(size=12),
    axis.text = element_text(size=10),
    plot.background = element_blank(),
    legend.background = element_blank(),
    legend.title = element_text(colour = "black", face = "italic"),
    legend.text = element_text(colour = "black", face = "italic"),
    strip.text.x = element_text(size = 14)
  )
}

palette5 <- c("#c8ddfa", "#8cb5ed", "#5890db",   "#2868bd", "#023578")

qBr <- function(df, variable, rnd) {
  if (missing(rnd)) {
    as.character(quantile(round(df[[variable]],0),
                          c(.01,.2,.4,.6,.8), na.rm=T))
  } else if (rnd == FALSE | rnd == F) {
    as.character(formatC(quantile(df[[variable]]), digits = 3),
                 c(.01,.2,.4,.6,.8), na.rm=T)
  }
}

q5 <- function(variable) {as.factor(ntile(variable, 5))}

#nearest neighbor function 
nn_function <- function(measureFrom,measureTo,k) {
  measureFrom_Matrix <- as.matrix(measureFrom)
  measureTo_Matrix <- as.matrix(measureTo)
  nn <-   
    get.knnx(measureTo, measureFrom, k)$nn.dist
  output <-
    as.data.frame(nn) %>%
    rownames_to_column(var = "thisPoint") %>%
    gather(points, point_distance, V1:ncol(.)) %>%
    arrange(as.numeric(thisPoint)) %>%
    group_by(thisPoint) %>%
    summarize(pointDistance = mean(point_distance)) %>%
    arrange(as.numeric(thisPoint)) %>% 
    dplyr::select(-thisPoint) %>%
    pull()
  
  return(output)  
}
```

# Data
what we used, how we collected
```{r Read Data}
#projected to NAD 1983 StatePlane Florida East FIPS 0901 Feet



#STUDY AREA
#miamiBound <- st_read("E:/Upenn/CPLN508/miami/2_Miami-Prediction/Raw Data/Municipal_Boundary.geojson") %>%
miamiBound <- st_read("/Users/annaduan/Documents/GitHub/2_Miami\ Prediction/Raw\ Data/Municipal_Boundary.geojson") %>%
  filter(NAME == "MIAMI BEACH" | NAME == "MIAMI") %>%
  st_union() %>%
  st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326, agr = "constant") %>%
  st_transform('ESRI:102658')



#STUDY AREA OSM (not projected so that it works)
#miamiBoundOSM <- st_read("E:/Upenn/CPLN508/miami/2_Miami-Prediction/Raw Data/Municipal_Boundary.geojson") %>%
miamiBoundOSM <- st_read("/Users/annaduan/Documents/GitHub/2_Miami\ Prediction/Raw\ Data/Municipal_Boundary.geojson") %>%
  filter(NAME == "MIAMI BEACH" | NAME == "MIAMI") %>%
  st_union()



#HOUSE DATA
#houses <- st_read("E:/Upenn/CPLN508/miami/2_Miami-Prediction/Raw Data/studentsData.geojson") %>%
houses <- st_read("/Users/annaduan/Documents/GitHub/2_Miami\ Prediction/Raw\ Data/studentsData.geojson") %>%
  st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326, agr = "constant") %>%
  st_transform('ESRI:102658') %>%
  st_centroid()




#HOUSE DATA OSM (Not projected)
#housesOSM <- st_read("E:/Upenn/CPLN508/miami/2_Miami-Prediction/Raw Data/studentsData.geojson")
housesOSM <- st_read("/Users/annaduan/Documents/GitHub/2_Miami\ Prediction/Raw\ Data/studentsData.geojson")



#CENSUS
census_api_key("d9ebfd04caa0138647fbacd94c657cdecbf705e9", install = TRUE, overwrite = TRUE)
#read in: vacant property, total housing units, mhhinc, white, population, owner occ, renter occ, travel time to work
acs <- 
  get_acs(geography = "tract", variables = c("B25002_003E", "B25001_001E", "B19013_001E", "B01001A_001E", "B01003_001E", "B07013_002E", "B07013_003E", "B08012_001E", "B25104_001E"), year=2018, state=12, county=086, geometry=T) %>% 
  st_transform('ESRI:102658')
#filter for Miami/Miami beach tracts
acs <- 
  rbind(
    st_centroid(acs)[miamiBound,] %>%
      st_drop_geometry() %>%
      left_join(acs) %>%
      st_sf() %>%
      mutate(inMiami = "YES"),
    st_centroid(acs)[miamiBound, op = st_disjoint] %>%
      st_drop_geometry() %>%
      left_join(acs) %>%
      st_sf() %>%
      mutate(inMiami = "NO")) %>%
  filter(inMiami == "YES") %>%
  dplyr::select(-inMiami)
#long to wide form
acs <- 
  acs %>%
  dplyr::select(-moe, -GEOID) %>%
  spread(variable, estimate) %>%
  dplyr::select(-geometry) %>%
  rename(vacantUnits = B25002_003, 
         totalUnits = B25001_001,
         medHHInc = B19013_001,
         white = B01001A_001, 
         population = B01003_001,
         ownerOcc = B07013_002, 
         renterOcc = B07013_003,
         timeToWork = B08012_001,
         monthhousingcost = B25104_001)
acs["119", "medHHInc"] = 33194   #input value from nearby tract in same neighborhod because NA was messing up MAE
acs %>% na.omit()


#mutate
acs <- 
  acs %>%
  mutate(pctVacant = ifelse(totalUnits > 0, vacantUnits / totalUnits, 0),
         pctWhite = ifelse(population > 0, white / population, 0),
         totalOcc = ownerOcc + renterOcc,
         pctRenterOcc = ifelse(totalOcc > 0, renterOcc / totalOcc, 0)) %>%
  dplyr::select(-totalUnits,-vacantUnits,-totalUnits,-population,-white, -ownerOcc, -renterOcc, -totalOcc)
  

#OSM BBOX (uses the non-projected base)
xmin = st_bbox(miamiBoundOSM)[[1]]
ymin = st_bbox(miamiBoundOSM)[[2]]
xmax = st_bbox(miamiBoundOSM)[[3]]  
ymax = st_bbox(miamiBoundOSM)[[4]]



#FOOD AND BEVERAGE SPOTS
 foodBev <- opq(bbox = c(xmin, ymin, xmax, ymax)) %>% 
  add_osm_feature(key = 'amenity', value = c("bar","pub","restaurant","cafe")) %>%
   osmdata_xml(filename = 'foodBev.osm')
 #project
 foodBev <- sf::st_read('foodBev.osm', layer = 'points') %>%
     st_as_sf(coords = c("LON", "LAT"), crs = EPSG:3857, agr = "constant") %>%
  st_transform('ESRI:102658')
 #filter for facilities in study area
 foodBev <- rbind(
    st_centroid(foodBev)[miamiBound,] %>%
      st_drop_geometry() %>%
      left_join(foodBev) %>%
      st_sf() %>%
      mutate(inMiami = "YES"),
    foodBev[miamiBound, op = st_disjoint] %>%
      st_drop_geometry() %>%
      left_join(foodBev) %>%
      st_sf() %>%
      mutate(inMiami = "NO")) %>%
  filter(inMiami == "YES") %>%
   dplyr::select(name)
 
 
 
#COASTLINE
Coastline<-opq(bbox = c(xmin, ymin, xmax, ymax)) %>% 
  add_osm_feature("natural", "coastline") %>%
  osmdata_sf()
#add to housesOSM and convert to miles, then add to houses
housesOSM <-
  housesOSM %>%  
  mutate(CoastDist=(geosphere::dist2Line(p=st_coordinates(st_centroid(housesOSM)),
                                        line=st_coordinates(Coastline$osm_lines)[,1:2])*0.00062137)[,1])
houses <-
  houses %>%
  mutate(distWater = housesOSM$CoastDist,
         SPSqFt = ifelse(!is.na(ActualSqFt)&!is.na(SalePrice), SalePrice / ActualSqFt, 0))



#PARKS
muniParks <- st_read("https://opendata.arcgis.com/datasets/16fe02a1defa45b28bf14a29fb5f0428_0.geojson") %>%
  st_as_sf(coords = c("LON", "LAT"), crs = 4326, agr = "constant") %>%
  st_transform('ESRI:102658') %>%
  dplyr::select(NAME, ADDRESS, CITY, CLASS, Shape__Area)

countyParks <- st_read("https://opendata.arcgis.com/datasets/aca1e6ff0f634be282d50cc2d534a832_0.geojson") %>%
  st_as_sf(coords = c("LON", "LAT"), crs = 4326, agr = "constant") %>%
  st_transform('ESRI:102658') %>%
    dplyr::select(NAME, ADDRESS, CITY, CLASS, Shape__Area)
parks <- bind_rows(muniParks, countyParks) %>% 
  filter(CITY == "Miami" | CITY == "Miami Beach") %>%
  mutate(counter = 1)



#SCHOOL DISTRICT
schoolDist <- st_read("https://opendata.arcgis.com/datasets/bc16a5ebcdcd4f3e83b55c5d697a0317_0.geojson") %>%
  st_as_sf(coords = c("LON", "LAT"), crs = 4326, agr = "constant") %>%
  st_transform('ESRI:102658') %>%
  dplyr::select(ID)



#PUBLIC SCHOOL CATCHMENT/ATTENDANCE ZONES
#elementary
elementary <- st_read("https://opendata.arcgis.com/datasets/19f5d8dcd9714e6fbd9043ac7a50c6f6_0.geojson") %>%
  st_as_sf(coords = c("LON", "LAT"), crs = 4326, agr = "constant") %>%
  st_transform('ESRI:102658') 
elementary <- rbind(
  st_centroid(elementary)[miamiBound,] %>%
    st_drop_geometry() %>%
    left_join(elementary) %>%
    st_sf() %>%
    mutate(inMiami = "YES"),
  st_centroid(elementary)[miamiBound, op = st_disjoint] %>%
    st_drop_geometry() %>%
    left_join(elementary) %>%
    st_sf() %>%
    mutate(inMiami = "NO")) %>%
  filter(inMiami == "YES") %>%
  dplyr::select(NAME)
#middle
middle <- st_read("https://opendata.arcgis.com/datasets/dd2719ff6105463187197165a9c8dd5c_0.geojson") %>%
  st_as_sf(coords = c("LON", "LAT"), crs = 4326, agr = "constant") %>%
  st_transform('ESRI:102658')
middle <- rbind(
  st_centroid(middle)[miamiBound,] %>%
    st_drop_geometry() %>%
    left_join(middle) %>%
    st_sf() %>%
    mutate(inMiami = "YES"),
  st_centroid(middle)[miamiBound, op = st_disjoint] %>%
    st_drop_geometry() %>%
    left_join(middle) %>%
    st_sf() %>%
    mutate(inMiami = "NO")) %>%
  filter(inMiami == "YES") %>%
  dplyr::select(NAME)
#high
high <- st_read("https://opendata.arcgis.com/datasets/9004dbf5f7f645d493bfb6b875a43dc1_0.geojson") %>%
  st_as_sf(coords = c("LON", "LAT"), crs = 4326, agr = "constant") %>%
  st_transform('ESRI:102658')
high <- rbind(
  st_centroid(high)[miamiBound,] %>%
    st_drop_geometry() %>%
    left_join(high) %>%
    st_sf() %>%
    mutate(inMiami = "YES"),
  st_centroid(high)[miamiBound, op = st_disjoint] %>%
    st_drop_geometry() %>%
    left_join(high) %>%
    st_sf() %>%
    mutate(inMiami = "NO")) %>%
  filter(inMiami == "YES") %>%
  dplyr::select(NAME)



#PUBLIC TRANSPORTATION
#bus
bus <- st_read("https://opendata.arcgis.com/datasets/021adadcf6854f59852ff4652ad90c11_0.geojson") %>%
  st_as_sf(coords = c("LON", "LAT"), crs = 4326, agr = "constant")  %>%
  st_transform('ESRI:102658')
bus <- rbind(
  bus[miamiBound,] %>%
    st_drop_geometry() %>%
    left_join(bus) %>%
    st_sf() %>%
    mutate(inMiami = "YES"),
  bus[miamiBound, op = st_disjoint] %>%
    st_drop_geometry() %>%
    left_join(bus) %>%
    st_sf() %>%
    mutate(inMiami = "NO")) %>%
  filter(inMiami == "YES")
#metro mover
metromover <- st_read("https://opendata.arcgis.com/datasets/aec76104165c4e879b9b0203fa436dab_0.geojson") %>%
  st_as_sf(coords = c("LON", "LAT"), crs = 4326, agr = "constant") %>%
  st_transform('ESRI:102658') 
metromover <- rbind(
  metromover[miamiBound,] %>%
    st_drop_geometry() %>%
    left_join(metromover) %>%
    st_sf() %>%
    mutate(inMiami = "YES"),
  metromover[miamiBound, op = st_disjoint] %>%
    st_drop_geometry() %>%
    left_join(metromover) %>%
    st_sf() %>%
    mutate(inMiami = "NO")) %>%
  filter(inMiami == "YES")
#metro rail
metrorail <- st_read("https://opendata.arcgis.com/datasets/ee3e2c45427e4c85b751d8ad57dd7b16_0.geojson") %>%
  st_as_sf(coords = c("LON", "LAT"), crs = 4326, agr = "constant") %>%
  st_transform('ESRI:102658') 
metrorail <- rbind(
  metrorail[miamiBound,] %>%
    st_drop_geometry() %>%
    left_join(metrorail) %>%
    st_sf() %>%
    mutate(inMiami = "YES"),
  metrorail[miamiBound, op = st_disjoint] %>%
    st_drop_geometry() %>%
    left_join(metrorail) %>%
    st_sf() %>%
    mutate(inMiami = "NO")) %>%
  filter(inMiami == "YES")



#CULTURE SPOTS
culture <- st_read("https://opendata.arcgis.com/datasets/70c48f0eb067448c8a787cfa1c1c3bb9_0.geojson") %>%
  st_as_sf(coords = c("LON", "LAT"), crs = 4326, agr = "constant") %>%
  st_transform('ESRI:102658') 
culture <- rbind(
  culture[miamiBound,] %>%
    st_drop_geometry() %>%
    left_join(culture) %>%
    st_sf() %>%
    mutate(inMiami = "YES"),
  culture[miamiBound, op = st_disjoint] %>%
    st_drop_geometry() %>%
    left_join(culture) %>%
    st_sf() %>%
    mutate(inMiami = "NO")) %>%
  filter(inMiami == "YES")



#COMMERCIAL PROPERTIES
#read, project
commercial <- st_read("https://opendata.arcgis.com/datasets/fb8303c577c24ea386a91be7329842be_0.geojson") %>%
  st_as_sf(coords = c("LON", "LAT"), crs = 4326, agr = "constant") %>%
  st_transform('ESRI:102658') 
#filter
commercial <- rbind(
  commercial[miamiBound,] %>%
    st_drop_geometry() %>%
    left_join(commercial) %>%
    st_sf() %>%
    mutate(inMiami = "YES"),
  commercial[miamiBound, op = st_disjoint] %>%
    st_drop_geometry() %>%
    left_join(commercial) %>%
    st_sf() %>%
    mutate(inMiami = "NO")) %>%
  filter(inMiami == "YES")



#FLOOD RISK ZONES
floodRisk <- st_read("https://opendata.arcgis.com/datasets/ef3bdd041b2e424695eb4dfe965966c4_0.geojson") %>%
  st_as_sf(coords = c("LON", "LAT"), crs = 4326, agr = "constant") %>%
  st_transform('ESRI:102658') 
#filter
 floodRisk <-
   rbind(
  st_centroid(floodRisk)[miamiBound,] %>%
    st_drop_geometry() %>%
    left_join(floodRisk) %>%
    st_sf() %>%
    mutate(inMiami = "YES"),
  st_centroid(floodRisk)[miamiBound, op = st_disjoint] %>%
    st_drop_geometry() %>%
    left_join(floodRisk) %>%
    st_sf() %>%
    mutate(inMiami = "NO")) %>%
  filter(inMiami == "YES") %>%
   dplyr::select(-inMiami, -SHAPE_Length, -ELEV, -FID) %>%
   dplyr::rename(FloodZone = FZONE, FloodHazard = ZONESUBTY)
 
 
 floodInsure <- st_read("https://opendata.arcgis.com/datasets/f589473ddada46e78d437aaf09205b04_0.geojson") %>%
  st_as_sf(coords = c("LON", "LAT"), crs = 4326, agr = "constant") %>%
  st_transform('ESRI:102658') 
filter
 floodInsure <-
   rbind(
  st_centroid(floodInsure)[miamiBound,] %>%
    st_drop_geometry() %>%
    left_join(floodInsure) %>%
    st_sf() %>%
    mutate(inMiami = "YES"),
  st_centroid(floodInsure)[miamiBound, op = st_disjoint] %>%
    st_drop_geometry() %>%
    left_join(floodInsure) %>%
    st_sf() %>%
    mutate(inMiami = "NO")) %>%
  filter(inMiami == "YES") %>%
   mutate(floodInsureType = PANELID)
 
 
 
#CONTAMINATED SITES
contaminated <- st_read("https://opendata.arcgis.com/datasets/43750f842b1e451aa0347a2ca34a61d7_0.geojson") %>%
  st_as_sf(coords = c("LON", "LAT"), crs = 4326, agr = "constant") %>%
  st_transform('ESRI:102658')
 contaminated <-
   rbind(
  st_centroid(contaminated)[miamiBound,] %>%
    st_drop_geometry() %>%
    left_join(contaminated) %>%
    st_sf() %>%
    mutate(inMiami = "YES"),
  st_centroid(contaminated)[miamiBound, op = st_disjoint] %>%
    st_drop_geometry() %>%
    left_join(contaminated) %>%
    st_sf() %>%
    mutate(inMiami = "NO")) %>%
  filter(inMiami == "YES")
 


#low income depressed area (county level no need to clip)
 #AD: Are these within our study area? I don't see much overlap and I feel this would result in a lot of NAs
#low_income_depressed <- st_read("https://opendata.arcgis.com/datasets/40119bfc50274c1da548ec8022e9a7a9_0.geojson") %>%
#  st_as_sf(coords = c("LON", "LAT"), crs = 4326, agr = "constant") %>%
#  st_transform('ESRI:102658')
#low_income_depressed <- rbind(
#  commercial[miamiBound,] %>%
#    st_drop_geometry() %>%
#    left_join(low_income_depressed) %>%
#    st_sf() %>%
#    mutate(inMiami = "YES"),
#  commercial[miamiBound, op = st_disjoint] %>%
#    st_drop_geometry() %>%
#    left_join(low_income_depressed) %>%
#    st_sf() %>%
#    mutate(inMiami = "NO")) %>%
#  filter(inMiami == "YES")

#neighborhood_revitalization <- st_read("https://opendata.arcgis.com/datasets/fe6f419e21264158b18eb77be9870d97_0.geojson") #%>%
#  st_as_sf(coords = c("LON", "LAT"), crs = 4326, agr = "constant") %>%
#  st_transform('ESRI:102658')
#neighborhood_revitalization <- rbind(
#  commercial[miamiBound,] %>%
#    st_drop_geometry() %>%
#    left_join(neighborhood_revitalization) %>%
#    st_sf() %>%
#    mutate(inMiami = "YES"),
#  commercial[miamiBound, op = st_disjoint] %>%
#    st_drop_geometry() %>%
#    left_join(neighborhood_revitalization) %>%
#    st_sf() %>%
#    mutate(inMiami = "NO")) %>%
#  filter(inMiami == "YES")
  
#neighborhood stability https://gis-mdc.opendata.arcgis.com/datasets/neighborhood-stabilization-program/data
#nbh_stability <- st_read("https://opendata.arcgis.com/datasets/5c0822e7c26d437dbc04103ddf05d2fc_0.geojson") %>%
#  st_as_sf(coords = c("LON", "LAT"), crs = 4326, agr = "constant") %>%
#  st_transform('ESRI:102658')

#install.packages("rmapshaper")
#library(rmapshaper)

#nbh_sta <- ms_clip(  #AD: what does this do?
#  nbh_stability,
#  clip = NULL,
#  bbox = c(xmin, ymin, xmax, ymax),
#  remove_slivers = FALSE,
#  force_FC = TRUE,
#  sys = FALSE
#)

#redevelopment area
#redev <- st_read("https://opendata.arcgis.com/datasets/38d923b6509547f8bde102e621100b53_0.geojson") %>%
#  st_as_sf(coords = c("LON", "LAT"), crs = 4326, agr = "constant") %>%
#  st_transform('ESRI:102658')
#redev <- rbind(
#  commercial[miamiBound,] %>%
#    st_drop_geometry() %>%
#    left_join(redev) %>%
#    st_sf() %>%
#    mutate(inMiami = "YES"),
#  commercial[miamiBound, op = st_disjoint] %>%
#    st_drop_geometry() %>%
#    left_join(redev) %>%
#    st_sf() %>%
#    mutate(inMiami = "NO")) %>%
#  filter(inMiami == "YES")

#1shop 
#BC:try this?
#AD: worked!
#shop_m <- st_read("/Users/annaduan/Documents/GitHub/2_Miami\ Prediction/Raw\ Data/shop_point.geojson") %>%
#shop_m <- st_read("E:/Upenn/CPLN508/miami/2_Miami-Prediction/Raw Data/shop_point.geojson") %>%
#  st_as_sf(coords = c("LON", "LAT"), crs = 4326, agr = "constant") %>%
#  st_transform('ESRI:102658')
#shop_mb <- st_read("/Users/annaduan/Documents/GitHub/2_Miami\ Prediction/Raw\ Data/shop_point_beach.geojson") %>%
#shop_mb <- st_read("E:/Upenn/CPLN508/miami/2_Miami-Prediction/Raw Data/shop_point_beach.geojson") %>%
#  st_as_sf(coords = c("LON", "LAT"), crs = 4326, agr = "constant") %>%
#  st_transform('ESRI:102658')
#sub_shop_m <- shop_m[, c("full_id", "osm_id", "osm_type", "name", "shop", "addr.city", "addr.street")]
#sub_shop_mb <- shop_mb[, c("full_id", "osm_id", "osm_type", "name", "shop", "addr.city", "addr.street")]
#shop <- rbind(sub_shop_m, sub_shop_mb)

#nece_shop <- shop %>% filter(shop %in% c("convenience", "supermarket", "department_store", "bakery", "greengrocer", "General Store"))  
#poor_shop <- shop %>% filter(shop %in% c("variety_store", "charity", "second_hand"))
#n_nece_shop <- setdiff(shop, rbind(nece_shop, poor_shop))
#n_nece_shop <- n_nece_shop[!(n_nece_shop$shop == "" | is.na(n_nece_shop$shop) | n_nece_shop$shop == "vacant"), ]

```


```{r Fig 1: TABLE summary stats}
#table of summary statistics with variable descriptions, sorted by category

housesSub <- houses %>%
  dplyr::select("AdjustedSqFt", "LotSize", "Bed", "Bath", "Stories", "age", "commercialProperties", "distWater", "foodEstablishments", "cultureSpots", "busStops", "parkArea", "timeToWork","monthhousingcost","pctVacant")
       
st_drop_geometry(housesSub)
stargazer(as.data.frame(housesSub), type="text", digits=1, title="Descriptive Statistics for Miami Houses", out = "Miami Data.txt")

```

```{r Wrangle Data, echo=FALSE}

drop <- c("x","TOD")
houses = houses[,!(names(houses) %in% drop)]
#AD: what is this? I'm assuming this was to get rid of extra error columns?

#TOD
 metroRBuffer <- metrorail %>% 
     st_buffer(0.5*5280) %>% #in feet
   st_union() %>% 
   st_as_sf() %>% 
   mutate(TOD = 1)
#mark as TOD or not
 houses$TOD <- houses %>% 
   st_centroid() %>% 
   st_join(metroRBuffer) %>% 
   mutate(TOD = ifelse(is.na(metroRBuffer), 0, 1)) %>%
   pull(TOD)
 

 
 
 
 #CONTAMINATION BUFFER
 #BC https://www.ncceh.ca/sites/default/files/Cemetery_setback_distances_surface_water_contamination-Oct_2017.pdf
 #maybe we use use a buffer of 250m?
 contamBuffer <- contaminated %>%
   st_buffer(800) %>%
   st_union() %>%
   st_as_sf() %>%
   mutate(contam = 1)
 houses$contaminated <- houses %>%
   st_join(contamBuffer) %>%
   mutate(contam = ifelse(is.na(contam), 0, 1)) %>%
   pull(contam)

 
 
#NEAREST NEIGHBOR (some are used for testing, to determine feature buffer distances)
 st_c <- st_coordinates
 houses <-
   houses %>% 
   mutate(
     #commercial properties NN
     commNN1 = nn_function(st_c(st_centroid(houses)), st_c(st_centroid(commercial)), 2),
     #park
     parkNN1 = nn_function(st_c(st_centroid(houses)), st_c(st_centroid(parks)), 1),
     parkNN2 = nn_function(st_c(st_centroid(houses)), st_c(st_centroid(parks)), 2),
     parkNN3 = nn_function(st_c(st_centroid(houses)), st_c(st_centroid(parks)), 3),
     parkNN4 = nn_function(st_c(st_centroid(houses)), st_c(st_centroid(parks)), 4),
     parkNN5 = nn_function(st_c(st_centroid(houses)), st_c(st_centroid(parks)), 5),
     #metro mover stations
     metroMNN5 = nn_function(st_c(st_centroid(houses)), st_c(metromover), 5),
     #metro rail stations
     metroRNN1 = nn_function(st_c(st_centroid(houses)), st_c(metrorail), 1),
     #bus stations
     busNN1 = nn_function(st_c(st_centroid(houses)), st_c(bus), 1),
     #culture
     cultureNN1 = nn_function(st_c(st_centroid(houses)), st_c(culture), 1),
     #food/drinks
     foodBevNN1 = nn_function(st_c(st_centroid(houses)), st_c(foodBev), 1),
     #daily food shopping place 5250.894
     neceshopNN3 = nn_function(st_c(st_centroid(houses)), st_c(nece_shop), 3),
     #poor people shopping place 8617.399
     poorshopNN1 = nn_function(st_c(st_centroid(houses)), st_c(poor_shop), 1),
     #leisure shopping place 4102.703
     nneceshopNN3 = nn_function(st_c(st_centroid(houses)), st_c(n_nece_shop), 3),
     #redevelopment 
    # redeNN1 = nn_function(st_c(st_centroid(houses)), st_c(st_centroid(redev)), 3)
     ) 

 
 
#COMMERCIAL BUFFER
 commercial <- commercial %>% 
   mutate(counter = 1) %>%
   dplyr::select(counter)
 #count properties within each buffer
houses$commercialProperties <-
   st_buffer(houses, 846) %>%
   aggregate(commercial, ., sum) %>% 
   st_drop_geometry() %>% 
  mutate(counter = ifelse(is.na(counter), 0, counter)) %>%
   pull(counter)
 


#FOOD AND BEV BUFFER
 foodBev <- foodBev %>% 
   mutate(counter = 1) %>%
   dplyr::select(counter)
 #count parks within each buffer
houses$foodEstablishments <-
   st_buffer(houses, 2774) %>%
   aggregate(foodBev, ., sum) %>% 
   st_drop_geometry() %>% 
    mutate(counter = ifelse(is.na(counter), 0, counter)) %>%
   pull(counter)



#CULTURE BUFFER
 culture <- culture %>% 
   mutate(counter = 1) %>%
   dplyr::select(counter)
 #count culture within each buffer
houses$cultureSpots <-
   st_buffer(houses, 774) %>%
   aggregate(culture, ., sum) %>% 
   st_drop_geometry() %>% 
   mutate(counter = ifelse(is.na(counter), 0, counter)) %>%
   pull(counter)




#METRORAIL BUFFER
 metrorail <- metrorail %>% 
   mutate(counter = 1) %>%
   dplyr::select(counter)
 #count stops within each buffer
houses$metrorailStops <-
   st_buffer(houses, 12076.7) %>%
   aggregate(metrorail, ., sum) %>% 
   st_drop_geometry() %>% 
  mutate(counter = ifelse(is.na(counter), 0, counter)) %>%
   pull(counter)



#METROMOVER BUFFER
 metromover <- metromover %>% 
   mutate(counter = 1) %>%
   dplyr::select(counter)
 #count metroM stops within each buffer
houses$metromoverStops <-
   st_buffer(houses, 18845) %>%
   aggregate(metromover, ., sum) %>% 
   st_drop_geometry() %>% 
   mutate(counter = ifelse(is.na(counter), 0, counter)) %>%
   pull(counter)



#BUS BUFFER
 bus <- bus %>% 
   mutate(counter = 1) %>%
   dplyr::select(counter)
 #count bus within each buffer
houses$busStops <-
   st_buffer(houses, 775) %>%
   aggregate(bus, ., sum) %>% 
   st_drop_geometry() %>% 
  mutate(counter = ifelse(is.na(counter), 0, counter)) %>%
   pull(counter)
 


 #PARKS BUFFER + AREA CALCULATION (using 1600ft buffer distance because the mean NN1 = 1600)
 #get centroids
 parkCentroids <- parks %>% 
   st_centroid(parks) %>%    #get centroids of park layer
  dplyr::select(counter)
 #count parks within each buffer
houses$parkCount <-
   st_buffer(houses, 1600) %>%
   aggregate(parkCentroids, ., sum) %>% 
   st_drop_geometry() %>% 
   mutate(counter = ifelse(is.na(counter), 0, counter)) %>%
   pull(counter)
#make buffer for each house
parkBuffer <- st_buffer(houses, 1600) %>%
  dplyr::select(Property.Address) %>%
  st_as_sf()
#calculate area of park space in each buffer
bufferedParks <- st_intersection(parkBuffer, parks) %>%
  group_by(Property.Address) %>%
  summarise() %>%
  mutate(parkArea = units::drop_units(st_area(.))) %>%
  st_drop_geometry()
#add park area back to houses file
houses <-
  left_join(houses, bufferedParks) 



#SCHOOL CATCHMENT CATEGORIES
 houses <-
   st_join(houses, elementary) %>%
   rename(elemCatch = 'NAME')
 
  houses <-
   st_join(houses, middle) %>%
   rename(middleCatch = 'NAME')
  
   houses <-
   st_join(houses, high) %>%
   rename(highCatch = 'NAME')
 

 
 #SCHOOL DISTRICT CATEGORIES
 houses <-
   st_join(houses, schoolDist) %>%
   rename(schoolDist = ID)
 
 
 #FLOOD INSURANCE CATEGORIES
floodInsure <- floodInsure %>%
  dplyr::select(floodInsureType)
houses <- houses %>%
  st_join(., floodInsure) %>%
  mutate(floodInsureType = ifelse(is.na(floodInsureType), "other", floodInsureType))



#ADD ACS DATA
houses <- 
  st_join(houses, acs) 
 
 
 
 
 #HOUSE AGE
houses <-
   houses %>%
   mutate(age = ifelse(is.na(YearBuilt), 0, (2020 - YearBuilt)))
 
 
 
 #MAKE CATEGORICAL VARIABLES
 houses <- 
  houses %>%
  mutate(Bed.cat = case_when(
                  Bed >= 0 & Bed < 3  ~ "Up to 2 Beds",
                  Bed >= 3 & Bed < 4  ~ "3 Beds",
                  Bed >= 4                    ~ "4+ Beds"))
 

 houses <- 
  houses %>%
  mutate(Bath.cat = case_when(
                  Bath < 2  ~ "Up to 1 Bathroom",
                  Bath == 2  ~ "2 Bathrooms",
                  Bath >= 3                    ~ "3+ Bathrooms"))
 
 
 houses <- 
  houses %>%
  mutate(Stories.cat = case_when(
                  Stories < 2  ~ "Up to 1 Stories",
                  Stories == 2  ~ "2 Stories",
                  Stories >= 3                    ~ "3+ Stories"))
 
 
  
 houses <- 
  houses %>%
  mutate(distWater.cat = case_when(
                  distWater < 1  ~ "Less than 1 Mile",
                  distWater >= 1                    ~ "More than 1 Mile"))
 
  
 houses <- 
  houses %>%
  mutate(parkArea.cat = case_when(
                  parkArea < 57000  ~ "Less than 57,000 SqFt",
                  parkArea >= 57000 & parkArea < 320000  ~ "57,000 - 320,000 SqFt",
                  parkArea >= 320000              ~ "More than 320,000 SqFt"))
 
 
 qplot(houses$parkArea, geom="histogram") +
   plotTheme()
 
 #OTHER HOUSE FEATURES
houses <- houses %>% 
  mutate(Pool = ifelse(str_detect(XF1, "Pool") | str_detect(XF2, "Pool") | str_detect(XF3, "Pool") | str_detect(XF1, "Whirlpool") | str_detect(XF2, "Whirlpool") | str_detect(XF3, "Whirlpool") | str_detect(XF1, "Jacuzzi") | str_detect(XF2, "Jacuzzi") | str_detect(XF3, "Jacuzzi"), "Pool", "No Pool"),
         Patio = ifelse(str_detect(XF1, "Patio") | str_detect(XF2, "Patio") | str_detect(XF3, "Patio"), "Patio", "No Patio"),
         Fence = ifelse(str_detect(XF1, "Fence") | str_detect(XF2, "Fence") | str_detect(XF3, "Fence"), "Fence", "No Fence"),
         Gazebo = ifelse(str_detect(XF1, "Gazebo") | str_detect(XF2, "Gazebo") | str_detect(XF3, "Gazebo"), "Gazebo", "No Gazebo"),
         Carport = ifelse(str_detect(XF1, "Carport") | str_detect(XF2, "Carport") | str_detect(XF3, "Carport"), "Carport", "No Carport"),
         Wall = ifelse(str_detect(XF1, "Wall") | str_detect(XF2, "Wall") | str_detect(XF3, "Wall"), "Wall", "No Wall"),
         Dock = ifelse(str_detect(XF1, "Dock") | str_detect(XF2, "Dock") | str_detect(XF3, "Dock"), "Dock", "No Dock"),
         )

#FIX NA VALUES
#zip
 houses <-
  houses %>%
  mutate(Mailing.Zip = as.numeric(Mailing.Zip),
         Mailing.Zip = ifelse(is.na(Mailing.Zip), 0, Mailing.Zip))

#School dist
 houses <-
   houses %>%
  mutate(elemCatch = ifelse(is.na(elemCatch), "other", elemCatch),
         middleCatch = ifelse(is.na(middleCatch), "other", middleCatch),
         highCatch = ifelse(is.na(highCatch), "other", highCatch),
         ) 
 
 #set of houses with missing ACS values - don't need this anymore
# houseNA <- subset(houses[c("441","579","580","581","1016","1372","1557","1853","2140","2557","2563","2571","2603","2786","2981","3050","3361"),])
 

 
#park
 houses <- houses %>%
     mutate(parkArea = ifelse(is.na(parkArea), 0, parkArea))
 
 #acs - here I found the location of NA values and gave these houses the ACS values of houses nearby/in same neighborhood
 houses["3487", "NAME"] = houses["1099", "NAME"]
 houses["3487","timeToWork"] =  houses["1099","timeToWork"]
houses["3487", "medHHInc"] = houses["1099", "medHHInc"]
houses["3487", "monthhousingcost"] = houses["1099", "monthhousingcost"]
houses["3487", "pctVacant"] = houses["1099", "pctVacant"]
houses["3487", "pctWhite"] = houses["1099", "pctWhite"]
houses["3487", "pctRenterOcc"] = houses["1099", "pctRenterOcc"]


houses[c("579","580","581","1016","1372","1557","1853","2140","2557","2563","2571","2603","2786","2981","3050","3361"), "NAME"] = houses["3458", "NAME"]
houses[c("579","580","581","1016","1372","1557","1853","2140","2557","2563","2571","2603","2786","2981","3050","3361"), "timeToWork"] = houses["3458", "timeToWork"]
houses[c("579","580","581","1016","1372","1557","1853","2140","2557","2563","2571","2603","2786","2981","3050","3361"), "medHHInc"] = houses["3458", "medHHInc"]
houses[c("579","580","581","1016","1372","1557","1853","2140","2557","2563","2571","2603","2786","2981","3050","3361"), "monthhousingcost"] = houses["3458", "monthhousingcost"]
houses[c("579","580","581","1016","1372","1557","1853","2140","2557","2563","2571","2603","2786","2981","3050","3361"), "pctVacant"] = houses["3458", "pctVacant"]
houses[c("579","580","581","1016","1372","1557","1853","2140","2557","2563","2571","2603","2786","2981","3050","3361"), "pctWhite"] = houses["3458", "pctWhite"]
houses[c("579","580","581","1016","1372","1557","1853","2140","2557","2563","2571","2603","2786","2981","3050","3361"), "pctRenterOcc"] = houses["3458", "pctRenterOcc"]

houses["441", c("NAME","timeToWork","medHHInc","monthhousingcost","pctVacant","pctWhite","pctRenterOcc")] = houses["2090", c("NAME","timeToWork","medHHInc","monthhousingcost","pctVacant","pctWhite","pctRenterOcc")]
 
houses %>%
  dplyr::select(-Property.Zip)


 
#payment/income

#i put monthly housing cost and household income in acs data, BUT NOT SURE HOW TO DEAL WITH THAT.
#AD - I dont htink we need employee_pay or low income depressed area because we already have income information by tract from ACS - at this stage in the project I think we need to focus on finalizing what we already have processed
#BC: OKAY

####low income depressed area##### 
#depressedBuffer <- st_buffer(houses, 0.5*5280) %>%
#  dplyr::select(Property.Address) %>%
#  st_as_sf()
#buffereddepressed <- st_intersection(depressedBuffer, low_income_depressed) %>%
#  group_by(Property.Address) %>%
#  summarise() %>%
#  st_drop_geometry()
#houses <-
#  left_join(houses, buffereddepressed)

##since depressed area has a wired shape, maybe we can do this too?
# houses$depressed <- houses %>% 
 #  st_join(depressedBuffer) %>% 
 #  mutate(depressed = ifelse(is.na(depressed), 0, 1)) %>%
 #  pull(depressed)
 
  
#revitalization
#reviBuffer <- st_buffer(houses, 0.5*5280) %>%
#  dplyr::select(Property.Address) %>%
#  st_as_sf()
#bufferedrevi <- st_intersection(reviBuffer, neighborhood_revitalization) %>%
#  group_by(Property.Address) %>%
#  summarise() %>%
#  mutate(parkArea = units::drop_units(st_area(.))) %>%
#  st_drop_geometry()
#houses <-
#  left_join(houses, bufferedrevi)

#neighborhood stability 

#BC: ??? NOT WORKING FOR NOW 
#sta_buffer <- st_buffer(houses, 0.5*5280) %>%
#  dplyr::select(Property.Address) %>%
#  st_as_sf()
#bufferedsta <- st_intersection(sta_buffer, nbh_stability) %>%
#  group_by(Property.Address) %>%
#  summarise() %>%
#  mutate(parkArea = units::drop_units(st_area(.))) %>%
#  st_drop_geometry()

#houses <-
  #left_join(houses, bufferedsta)

#redevelopment 

#redev <- as.data.frame(redev)
#houses$redev <- ifelse(st_intersects(houses$geometry, redev$geometry), 1, 0)

#shop 

#nece_shop buffer
#nece_shop <- nece_shop %>% 
#   mutate(counter = 1) %>%
#   dplyr::select(counter)
#houses$nece_shop_buffer <-
#   st_buffer(houses, 10*5280) %>%
#   aggregate(nece_shop, ., sum) %>% 
#   st_drop_geometry() %>% 
#   mutate(counter = ifelse(is.na(counter), 0, counter)) %>%
#   pull(counter)

#poor_shop buffer
#poor_shop <- poor_shop %>% 
#   mutate(counter = 1) %>%
#   dplyr::select(counter)
#houses$poor_shop_buffer <-
#   st_buffer(houses, 10*5280) %>%
#   aggregate(poor_shop, ., sum) %>% 
#   st_drop_geometry() %>% 
#   mutate(counter = ifelse(is.na(counter), 0, counter)) %>%
#   pull(counter)

#n_nece_shop buffer
#n_nece_shop <- n_nece_shop %>% 
#   mutate(counter = 1) %>%
#   dplyr::select(counter)
#houses$n_nece_shop_buffer <-
#   st_buffer(houses, 10*5280) %>%
#   aggregate(n_nece_shop, ., sum) %>% 
#   st_drop_geometry() %>% 
#   mutate(counter = ifelse(is.na(counter), 0, counter)) %>%
#   pull(counter)

```

```{r Fig 2: Correlation Matrix}

#correlation matrix
numericVars <- 
  select_if(st_drop_geometry(houses), is.numeric) %>% na.omit()


ggcorrplot(
  round(cor(numericVars), 1), 
  p.mat = cor_pmat(numericVars),
  colors = c("#25CB10", "white", "#FA7800"),
  type="lower",
  insig = "blank") +  
    labs(title = "Correlation across numeric variables") 

```

# Methods
```{r Fig 3: SCATTERPLOT home price correlation}

#1: distWater
ggplot(data = housesKnown, aes(x = distWater, y = SalePrice)) +
  geom_point(size=2, shape=20)  +
  geom_smooth(method = "lm", se=F, colour = "green")

#2: parkArea
ggplot(data = housesKnown, aes(x = parkArea, y = SalePrice)) +
  geom_point(size=2, shape=20) +
  geom_smooth(method = "lm", se=F, colour = "green")

#3: flood insurance type
ggplot(data = housesKnown, aes(x = floodInsureType, y = SalePrice)) +
  geom_point(size=2, shape=20)

#4: bus stops - interesting that houses with more nearby cost less - maybe because they're near the street #BC:maybe, or maybe the distribution of bus stops are intended to be in those poor neighborhood/depressed area? #AD: possibly!
ggplot(data = housesKnown, aes(x = busStops, y = SalePrice)) +
  geom_point(size=2, shape=20) +
  geom_smooth(method = "lm", se=F, colour = "green")

```

```{r Fig 4: MAP Sale Price}
#map of your dependent variable (sale price)
  #water is just for mapping visuals
water <- st_read("https://opendata.arcgis.com/datasets/bf9de3192c9c4e458d1453f6d4c88d6c_0.geojson") %>%
 st_as_sf(coords = c("LON", "LAT"), crs = 4326, agr = "constant") %>%
  st_transform('ESRI:102658') %>%
  st_union() %>%
  st_intersection(.,miamiBound)

ggplot() +
  geom_sf(data = acs, fill = "transparent", colour = "light blue") +
  geom_sf(data = water, fill = "light blue", colour = "light blue") +
  geom_sf(data = housesKnown, aes(colour = q5(SalePrice))) +
  scale_fill_manual(values = palette5) +
  mapTheme()
```

```{r Fig 5: MAP 3 Independent Variables}

#3 maps of 3 of your most interesting independent variables

ggplot() +
  geom_sf(data = acs, fill = "gray90", colour = "white") +
  geom_sf(data = housesKnown, aes(colour = q5(parkArea))) +
  scale_fill_manual(values = palette5) +
  labs(title = "Nearby Park Area", subtitle = "Miami, FL") +
  mapTheme()

ggplot() +
  geom_sf(data = acs, aes(fill = q5(medHHInc))) +
  geom_sf(data = housesKnown, aes(colour = q5(floodInsureType))) +
  scale_fill_manual(values = palette5) +
   labs(title = "Flood Insurance Rating", subtitle = "Miami, FL") +
  mapTheme()

#AdjustedSqFt
ggplot() + 
  geom_sf(data = houses, aes(colour = q5(AdjustedSqFt))) +
  scale_fill_manual(values = palette5) +
  mapTheme()


#?TOD
ggplot() + 
  geom_sf(data = houses, aes(colour = TOD)) +
  scale_fill_manual(values = palette5) +
  mapTheme()

#SPSqFt
ggplot() + 
  geom_sf(data = houses, aes(colour = q5(SPSqFt))) +
  scale_fill_manual(values = palette5) +
  mapTheme()


#commNN1
ggplot() + 
  geom_sf(data = houses, aes(colour = q5(commNN1))) +
  scale_fill_manual(values = palette5) +
  mapTheme()

#metrorailStops
ggplot() + 
  geom_sf(data = houses, aes(colour = metrorailStops)) +
  scale_fill_manual(values = palette5) +
  mapTheme()

#timeToWork - interesting because it doesn't seem related to distance from center city
ggplot() + 
  geom_sf(data = houses, aes(colour = q5(timeToWork))) +
  scale_fill_manual(values = palette5) +
  mapTheme()

#medHHInc - seeems correlated with distance from water
ggplot() + 
  geom_sf(data = houses, aes(colour = q5(medHHInc))) +
  scale_fill_manual(values = palette5) +
  mapTheme()

#pctRenterOcc - also related to distance from water
ggplot() + 
  geom_sf(data = houses, aes(colour = q5(pctRenterOcc))) +
  scale_fill_manual(values = palette5) +
  mapTheme()

#Pool - funny that there's more pools close to beach
ggplot() + 
  geom_sf(data = houses, aes(colour = q5(Pool))) +
  scale_fill_manual(values = palette5) +
  mapTheme()

```

```{r Designing Regression}


 cor.test(houses$parkArea, houses$SalePrice, method = "pearson")

 
 #1: random - 0.826 - LETS DO THIS ONE
 #BC: CHECK THIS OUT, SO SURPRISED!!!
 #AD: even higher now!
 #MATT: MAE cross-validation 
 reg1 <- lm(SalePrice ~ ., data = st_drop_geometry(houses) %>% 
             dplyr::select(SalePrice, LivingSqFt, Bed.cat, Bath.cat, LotSize, Stories.cat, Zoning, age, Bldg, timeToWork, parkArea, medHHInc, pctVacant, foodEstablishments, metromoverStops, Pool, Dock, Patio, floodInsureType, highCatch))
 summary(reg1)
 #what is bldg? Bldg,
```

```{r Train the regression}
#MATT:refine neighborhood data
#read FL neighborhoods
#nhoods_fl <- aoi_boundary_HARV <- st_read("E:/Upenn/CPLN508/miami/zillow_nghbrhd_feb17/zillow_nghbrhd_feb17.shp")
nhoods_fl <- aoi_boundary_HARV <- st_read("/Users/annaduan/Documents/GitHub/Miami-Oct12/Raw\ Data/zillow_nghbrhd_feb17/zillow_nghbrhd_feb17.shp")
nhoods_mb <- subset(nhoods_fl, CITY == "MIAMI BEACH")%>%
  st_as_sf(coords = c("LON", "LAT"), crs = 4326, agr = "constant") %>%
  st_transform('ESRI:102658')
nhoods_m <- subset(nhoods_fl, CITY == "MIAMI")%>%
  st_as_sf(coords = c("LON", "LAT"), crs = 4326, agr = "constant") %>%
  st_transform('ESRI:102658')


#Join neighborhoods
nhoods <- rbind(nhoods_mb, nhoods_m)
nhoods <- nhoods %>%
  dplyr::select(NAME) %>%
  rename(neighborhood = NAME)
houses <- houses %>% st_join(., nhoods, join = st_within)
#BC: I THINK WE SHOULD JOIN NEIGHBORHOODS BEFORE WE DO THE SEPERATING. VARIABLES "NAMES.Y" MEANS NEIGHBORHOOD NAME AND WE WILL USE THIS LATER
#AD: makes sense. I added some code to get rid of all columns other than neighborhood name. Also renamed NAMES.Y as "neighborhood" to make things clearer.


#Separate by toPredict
housesKnown <- houses %>%     #AD: we should do this only to known sale prices
  filter(.,toPredict == 0)
housesUnknown <- houses %>%
  filter(.,toPredict ==1)
#Make train and test sets
inTrain <- createDataPartition(
              y = paste(housesKnown$Zoning, housesKnown$floodInsureType, housesKnown$neighborhood), 
              p = .60, list = FALSE)
miami.training <- housesKnown[inTrain,] 
miami.test <- housesKnown[-inTrain,]  


#Training regression #edit the variables
reg.training <- 
  lm(SalePrice ~ ., data = st_drop_geometry(miami.training) %>% 
                             dplyr::select(SalePrice, LivingSqFt, Bed.cat, Bath.cat, LotSize, Stories.cat, Zoning, age, timeToWork, parkArea, medHHInc, pctVacant, foodEstablishments, metromoverStops, Pool, Dock, Patio, floodInsureType, highCatch))
summary(reg.training)

 reg3 <- lm(SalePrice ~ ., data = st_drop_geometry(houses) %>% 
             dplyr::select(SalePrice, ActualSqFt, Zoning, Stories.cat, elemCatch, Bath.cat, Pool, medHHInc, Dock, Bed.cat, middleCatch, age, pctVacant, pctRenterOcc, monthhousingcost, Patio, Wall, foodEstablishments, metromoverStops, metrorailStops, parkArea, TOD, floodInsureType, schoolDist, distWater))
 summary(reg3)
```

# Results
```{r Fig 6: TABLE Training Set lm}
#polished table of  (training set) lm summary results (coefficients, R2 etc)
stargazer(reg.training, type="text", digits=1, title="LM of Training Data", out = "Training LM.txt")
```

```{r Test the regression}
#Test regression on miami.test
miami.test <-
  miami.test %>%
  mutate(Regression = "Baseline Regression",
         SalePrice.Predict = predict(reg.training, miami.test), #730348.4
         SalePrice.Error = SalePrice.Predict - SalePrice, #60608.35
         SalePrice.AbsError = abs(SalePrice.Predict - SalePrice), #185887  - much lower now that we only use known SalePrices
         SalePrice.APE = (abs(SalePrice.Predict - SalePrice)) / SalePrice.Predict)%>% #0.7169534
  filter(SalePrice < 5000000) 

#Mean error and APE 432255.1   0.3407089   443611.7 0.1643853 467809 -0.0241117
  #AD: what are the values in line above?
mean(miami.test$SalePrice.AbsError, na.rm = T)
mean(miami.test$SalePrice.APE, na.rm = T)
mean(miami.test$SalePrice.Predict, na.rm = T)


#Predicted price vs % error
#BC: THIS SEEMS GREAT!
ggplot(data = miami.test, aes(x = SalePrice.Predict, y = SalePrice.APE)) + geom_point()
```

```{r Fig 7: TABLE of MAE and MAPE for single test set}
#AD: not sure how to do this
length(reg.cv$resample$MAE)
max(reg.cv$resample$MAE)#949097
reg.cv$resample[80,]
min(reg.cv$resample$MAE)#237439.9
reg.cv$resample[75,]

stargazer(min(reg.cv$resample$MAE), type="text", digits=1, title="LM of Training Data", out = "Training LM.txt")

reg.cv.rs.min <- as.data.frame(reg.cv$resample[75,])
#stargazer(reg.cv.rs.min, type="text", digits=1, title="LM of Training Data", out = "Training LM.txt")
library(kableExtra)
reg.cv.rs.min %>%
  gather(Variable, Value) %>%
  #filter(Variable == "MAE" | Variable == "RMSE") %>%
  group_by(Variable) %>%
    spread(Variable, Value) %>%
    kable() %>%
    kable_styling()
```
## Generalizability
```{r K-Folds Cross Validation Test}
#K Folds test 
fitControl <- trainControl(method = "cv", number = 100)
set.seed(825)

reg.cv <- 
  train(SalePrice ~ ., data = st_drop_geometry(housesKnown) %>% 
                                dplyr::select(SalePrice, LivingSqFt, Bed.cat, Bath.cat, LotSize, Stories.cat, Zoning, Bldg, age, timeToWork, parkArea, medHHInc, pctVacant, foodEstablishments, metromoverStops, Pool, Dock, Patio, floodInsureType, highCatch), 
     method = "lm", trControl = fitControl, na.action = na.pass)

#reg.cv.predict <- 
#  predict(SalePrice ~ ., data = st_drop_geometry(housesKnown) %>% 
#                                dplyr::select(SalePrice, LivingSqFt, Bed.cat, Bath.cat, LotSize, Stories.cat, Zoning, #Bldg, age, timeToWork, parkArea, medHHInc, pctVacant, foodEstablishments, metromoverStops, Pool, Dock, Patio, #floodInsureType, highCatch), 
#     method = "lm", trControl = fitControl, na.action = na.pass)

# reg.cv
# RMSE      Rsquared   MAE     
# 423694   0.9554   230440
#3503 samples
#  24 predictor

#k-fold function online
kfold.MLR = function(fit,k=10,data=fit$model) {
  sum.sqerr = rep(0,k)
  sum.abserr = rep(0,k)
  sum.pererr = rep(0,k)
  y = fit$model[,1]
  x = fit$model[,-1]
  n = nrow(data)
  folds = sample(1:k,nrow(data),replace=T)
  for (i in 1:k) {
    fit2 <- lm(formula(fit),data=data[folds!=i,])
    ypred = predict(fit2,newdata=data[folds==i,])
    sum.sqerr[i] = sum((y[folds==i]-ypred)^2)
    sum.abserr[i] = sum(abs(y[folds==i]-ypred))
    sum.pererr[i] = sum(abs(y[folds==i]-ypred)/y[folds==i])
  }
  cv = return(data.frame(RMSEP=sqrt(sum(sum.sqerr)/n),
                         MAE=sum(sum.abserr)/n,
             MAPE=(sum(sum.pererr)/n)*100))
}


```

```{r Fig 8: HISTOGRAM results of cross-validation tests}

#This includes mean and standard deviation MAE. 
#Do 100 folds and plot your cross-validation MAE as a histogram
ggplot(reg.cv$MAE, geom="histogram") +  #should this be average error for each fold? not working properly..
  plotTheme()

library(lindia)
gg_reshist(reg.cv)      #try #2
# specify number of bins
gg_reshist(reg.cv, bins = 20)
```
## Do errors cluster?
```{r Spatial Lag}
library(knitr)
library(kableExtra)
library(scales)

############test for clustering##############
coords <- st_coordinates(housesKnown) 
neighborList <- knn2nb(knearneigh(coords, 5)) #5 nearest neighborhoods, we can change that 
spatialWeights <- nb2listw(neighborList, style="W") #not sure what is W here
housesKnown$lagPrice <- lag.listw(spatialWeights, housesKnown$SalePrice)
plot(housesKnown$SalePrice, housesKnown$lagPrice) 


coords.test <-  st_coordinates(miami.test) 
neighborList.test <- knn2nb(knearneigh(coords.test, 5))
spatialWeights.test <- nb2listw(neighborList.test, style="W")



#BC: I think this regression is not accurate
#AD: how come?

```

```{r morans I}
################Moran's I##################
moranTest <- moran.mc(miami.test$SalePrice.Error, 
                      spatialWeights.test, nsim = 999)

ggplot(as.data.frame(moranTest$res[c(1:999)]), aes(moranTest$res[c(1:999)])) +
  geom_histogram(binwidth = 0.01) +
  geom_vline(aes(xintercept = moranTest$statistic), colour = "#FA7800",size=1) +
  scale_x_continuous(limits = c(-1, 1)) +
  labs(title="Observed and permuted Moran's I",
       subtitle= "Observed Moran's I in orange",
       x="Moran's I",
       y="Count",
       caption="Public Policy Analytics, Figure x.x") +
  plotTheme()

```

```{r 10: MAP of residuals for test set}

#map of your residuals for your test set
#AD: not sure waht this is

#Moran's I test

#Plot: spatial lag in errors
#AD: I'm not super clear on this section

miami.test %>% 
  ggplot(aes(SalePrice.Error, SalePrice)) +       #what's this for?
  geom_point() +
  stat_smooth(aes(SalePrice.Error, SalePrice), 
            method = "lm", se = FALSE, size = 1, colour="#25CB10")+
  plotTheme() + theme(plot.title = element_text(size = 18, colour = "black")) 
  

miami.test %>%                
  mutate(lagPriceError = lag.listw(spatialWeights.test, SalePrice.Error)) +  #AD: not working for me
  ggplot(aes(lagPriceError, SalePrice)) +
  geom_point() +
  stat_smooth(aes(lagPriceError, SalePrice), 
             method = "lm", se = FALSE, size = 1, colour="#FA7800")+
  plotTheme() + theme(plot.title = element_text(size = 18, colour = "black")) 


miami.test %>% 
  mutate(lagPriceError = lag.listw(spatialWeights.test, SalePrice.Error)) %>%   #AD: not working for me
  ggplot(aes(lagPriceError, SalePrice.Error)) +
  geom_point() +
  stat_smooth(aes(lagPriceError,SalePrice.Error), 
             method = "lm", se = FALSE, size = 1, colour="red")+
  plotTheme() + theme(plot.title = element_text(size = 18, colour = "black")) 


```
## Accounting for neighborhood variance
```{r Neighborhood Regression}
left_join(
  st_drop_geometry(miami.test.nood) %>%
    group_by(neighborhood) %>%
    summarize(meanPrice = mean(SalePrice, na.rm = T)),     #AD: should both columns be the same?
  mutate(miami.test, predict.fe = 
                        predict(lm(SalePrice ~ neighborhood, data = miami.test.nhood), 
                        miami.test)) %>%
    st_drop_geometry %>%
    group_by(neighborhood) %>%
      summarize(meanPrediction = mean(predict.fe))) %>%
      kable() %>% 
  kable_styling()


#Make new neighborhood regression
reg.nhood <- lm(SalePrice ~ ., data = as.data.frame(miami.training) %>% 
                                 dplyr::select(neighborhood, SalePrice, LivingSqFt, Bed.cat, Bath.cat, LotSize, Stories.cat, Zoning, Bldg, age, timeToWork, parkArea, medHHInc, pctVacant, foodEstablishments, metromoverStops, Pool, Dock, Patio, floodInsureType, highCatch))
summary(reg.nhood)


miami.test.nhood <-
  miami.test %>%
  mutate(Regression = "Neighborhood Effects",
         SalePrice.Predict = predict(reg.nhood, miami.test), #613237.3
         SalePrice.Error = SalePrice - SalePrice.Predict, # -108442.4      
         SalePrice.AbsError = abs(SalePrice - SalePrice.Predict), # 491238.7
         SalePrice.APE = (abs(SalePrice - SalePrice.Predict)) / SalePrice.Predict)%>% #0.7109973
  filter(SalePrice < 5000000)

#Check accuracy 
bothRegressions <- 
  rbind(
    dplyr::select(miami.test, starts_with("SalePrice"), Regression, neighborhood) %>%
      mutate(lagPriceError = lag.listw(spatialWeights.test, SalePrice.Error)),
    dplyr::select(miami.test.nhood, starts_with("SalePrice"), Regression, neighborhood) %>%
      mutate(lagPriceError = lag.listw(spatialWeights.test, SalePrice.Error)))   


st_drop_geometry(bothRegressions) %>%
  gather(Variable, Value, -Regression, -neighborhood) %>%
  filter(Variable == "SalePrice.AbsError" | Variable == "SalePrice.APE") %>%
  group_by(Regression, Variable) %>%
    summarize(meanValue = mean(Value, na.rm = T)) %>%
    spread(Variable, meanValue) %>%
    kable()
# BC: 
#|Regression           | SalePrice.AbsError| SalePrice.APE|
#|:--------------------|------------------:|-------------:|
#|Baseline Regression  |           185887.0|     0.7169534|
#|Neighborhood Effects |           190606.9|     0.0981914|


```

```{r Fig 9:PLOT predicted prices as a function of observed prices}
bothRegressions %>%
  dplyr::select(SalePrice.Predict, SalePrice, Regression) %>%
    ggplot(aes(SalePrice, SalePrice.Predict)) +
  geom_point() +
  stat_smooth(aes(SalePrice, SalePrice), 
             method = "lm", se = FALSE, size = 1, colour="#FA7800") + 
  stat_smooth(aes(SalePrice.Predict, SalePrice), 
              method = "lm", se = FALSE, size = 1, colour="#25CB10") +
  facet_wrap(~Regression) +
  labs(title="Predicted sale price as a function of observed price",
       subtitle="Orange line represents a perfect prediction; Green line represents prediction") +
  plotTheme() + theme(plot.title = element_text(size = 18, colour = "black"))

```
## Final predictions
```{r Final prediction}

#876 rows 
#filter by toPredict = 1
housesPredictions <-                   
  houses %>%
  mutate(SalePrice.predict = predict(reg.nhood, houses),
         TeamName = 'Panda')

housesPredictions <- housesPredictions[,c("Folio", "SalePrice.predict", "TeamName")] #AD: what do you think!:)
#BC: I got this error when running this
#Problem with `mutate()` input `SalePrice.Predict`.
#i prediction from a rank-deficient fit may be misleading
#i Input `SalePrice.Predict` is `predict(reg.nhood, miami.test, TeamName = )`.prediction from a rank-deficient fit may be misleading
#AD: thats's fine I think, I've seen this warning a lot of times. It worked though!

allHouses <- houses %>%    #working on adding back to all houses, not done yet
  filter(toPredict == 0) %>%
  st_join(housesPredictions)
```

```{r 11: map of predicted values}
#11 Provide a map of your predicted values for where toPredict is both 0 and 1. for all houses
ggplot() +
  geom_sf(data = housesPredictions, aes(colour = q5(SalePrice.predict))) +
  scale_fill_manual(values = palette5) +
  mapTheme()
# BC: if it says one map for your predicted values for all houses, maybe it's simply asking for this?

```

```{r 12: Using the test set predictions, provide a map of MAPE by neighborhood}
#Using the test set predictions, provide a map of mean absolute percentage error (MAPE) by neighborhood
names(bothRegressions)[names(bothRegressions) == "neighborhood"] <- "neighborhood"
st_drop_geometry(bothRegressions) %>%
  group_by(Regression, neighborhood) %>%
  summarise(mean.MAPE = mean(SalePrice.APE, na.rm = T)) %>%
  ungroup() %>% 
  left_join(nhoods) %>%
    st_as_sf() %>%
    ggplot() + 
      geom_sf(aes(fill = mean.MAPE)) +
      geom_sf(data = bothRegressions, colour = "black", size = .5) +
      facet_wrap(~Regression) +
      scale_fill_gradient(low = palette5[1], high = palette5[5],
                          name = "MAPE") +
      labs(title = "Mean test set MAPE by neighborhood") +
      mapTheme()

```

```{r 13: Scatterplot of MAPE by neighborhood as a function of mean price by neighborhood}
#AD: not sure how to do this

scatter_hood <- 
    miami.test.nhood %>%
    group_by(NAME.y) %>%
    dplyr::select(NAME.y, SalePrice.APE, SalePrice.Predict)

mean_sca_hd <- 
  scatter_hood %>%
  group_by(NAME.y) %>%
  summarise_at(vars("SalePrice.APE", "SalePrice.Predict"), mean)

plot(mean_sca_hd$SalePrice.Predict, mean_sca_hd$SalePrice.APE, main="MAPE by neighborhood as a function of mean price by neighborhood", xlab="mean price by neighborhood", ylab="MAPE by neighborhood")
  
#https://r-graphics.org/recipe-scatter-labels or we can use the method below:

scatter_mae_mean <- ggplot(mean_sca_hd, aes(x = SalePrice.Predict, y = SalePrice.APE)) +
    geom_point()

scatter_mae_mean +
  annotate("text", x = 820000, y = -11.7, label = "UPPER EASTSIDE") +
  annotate("text", x = 330000, y = -6.5, label = "LITTLE HAITI")+
  annotate("text", x = 1300000.82, y = 6.85325579, label = "NAUTILUS")+
  annotate("text", x = 631682.30, y = 3.57218432, label = "BISCAYNE POINT")+
  annotate("text", x = 1557855.78, y = 2.81996319, label = "LA GORCE")+
  annotate("text", x = 2031665.51, y = 1.95167248, label = "WYNWOOD - EDGEWATER")+
  annotate("text", x = 890031.19, y = -2.16394539, label = "OVERTOWN")	

```

## Does this model work equally for different demographic groups?
```{r 14: race and income}
#RACE & INCOME
  #make new layer
acsRaceIncome <- 
  acs %>%
  mutate(raceContext= ifelse(pctWhite > .5, "Majority White", "Majority Non-White"),
         incomeContext = ifelse(medHHInc > 49256.56, "High Income", "Low Income")) 
#context
grid.arrange(ncol = 2,
  ggplot() + geom_sf(data = na.omit(acsRaceIncome), aes(fill = raceContext)) +
    scale_fill_manual(values = c("#25CB10", "#FA7800"), name="Race Context") +
    labs(title = "Race Context") +
    mapTheme() + theme(legend.position="bottom"), 
  ggplot() + geom_sf(data = na.omit(acsRaceIncome), aes(fill = incomeContext)) +
    scale_fill_manual(values = c("#25CB10", "#FA7800"), name="Income Context") +
    labs(title = "Income Context") +
    mapTheme() + theme(legend.position="bottom"))
#tables
st_join(bothRegressions, acsRaceIncome) %>% 
  filter(!is.na(raceContext)) %>%
  group_by(Regression, raceContext) %>%
  summarize(mean.MAPE = scales::percent(mean(SalePrice.APE, na.rm = T))) %>%
  st_drop_geometry() %>%
  spread(raceContext, mean.MAPE) %>%
  kable(caption = "Test set MAPE by neighborhood racial context")

st_join(bothRegressions, acsRaceIncome) %>% 
  filter(!is.na(incomeContext)) %>%
  group_by(Regression, incomeContext) %>%
  summarize(mean.MAPE = scales::percent(mean(SalePrice.APE, na.rm = T))) %>%
  st_drop_geometry() %>%
  spread(incomeContext, mean.MAPE) %>%
  kable(caption = "Test set MAPE by neighborhood income context")

#Regression	Majority Non-White	Majority White
#Baseline Regression	-761%	93%
#Neighborhood Effects	36%	81%

#Regression	High Income	Low Income
#Baseline Regression	137%	-282%
#Neighborhood Effects	-31%	163%
<<<<<<< Updated upstream
=======

#####MAKE PREDICTIONS FOR HOUSE SALE PRICES######
#876 rows 
#filter by toPredict = 1
miami.test.result <-       
  miami.test.nhood %>%
  mutate(SalePricePredict = SalePrice.Predict,
         TeamName = 'somename')
miami.predict.result <- miami.test.result[,c('SalePricePredict', 'TeamName')]
#BC: I got this error when running this
#Problem with `mutate()` input `SalePrice.Predict`.
#i prediction from a rank-deficient fit may be misleading
#i Input `SalePrice.Predict` is `predict(reg.nhood, miami.test, TeamName = )`.prediction from a rank-deficient fit may be misleading
>>>>>>> Stashed changes

```

# Discussion
